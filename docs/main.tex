\documentclass[12pt, twoside, hidelinks, a4paper]{article}

\usepackage[]{geometry}
\geometry{inner=30mm, outer=20mm, top=23mm, bottom=23mm}

\usepackage{mystyle}
\pagestyle{headings}

\usepackage{fancyhdr}
\fancyhf{}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
% numery stron: lewa do lewego, prawa do prawego
\fancyfoot[LE,RO]{\thepage}

\fancypagestyle{plain}
{
   \fancyhf{}
\renewcommand{\headrulewidth}{0pt}
% numery stron: lewa do lewego, prawa do prawego
\fancyfoot[LE,RO]{\thepage}
}

\usepackage{pdfpages}
\usepackage{amsfonts}
%\renewcommand{\familydefault}{\sfdefault}
\setlength\parindent{1cm}

\usepackage{indentfirst}
\usepackage[affil-it]{authblk}
\usepackage{smartdiagram}
\usepackage{metalogo}
\usepackage{moreverb}
\usepackage{multicol}

\begin{document}
    \setstretch{1.15}
 	\pagenumbering{arabic}

\author{Artur Błaszczyk, Marcin Waszak, Artur Zygadło}
\title{PORR -- sprawozdanie z projektu}
\date{12 stycznia 2019}
\affil{Wydział Elektroniki i Technik Informacyjnych, Politechnika Warszawska}


\maketitle

\begin{abstract}
Celem sprawozdania jest przedstawienie przykładowych sposobów implementacji zrównoleglonego algorytmu wyszukiwania liczb pierwszych w zadanym przedziale. Zaprezentowane zostaną kolejno: wersja jednowątkowa, POSIX threads, C++11 threads oraz OpenMP, a w dalszej części także MPI oraz CUDA. W ostatnim rozdziale znajduje się prezentacja rezultatów i wnioski. 
\end{abstract}

\section{Zadanie}
Zadanie polega na znajdowaniu liczb pierwszych w zadanym przedziale przy użyciu wybranych mechanizmów programowania równoległego.

\section{Implementacja}
Zadanie zostało wykonane w języku C++, ponieważ wspiera on programowanie obiektowe oraz posiada on gotowe struktury danych w ramach STL. Program został napisany z myślą o kompilacji w środowisku \textbf{GNU/Linux}. Wykorzystano system budowania \textbf{CMake}. W ramach pracy zostały rozpatrzone następujące wersje zadania:

\begin{multicols}{2}
\begin{itemize}
\item jednowątkowa,
\item POSIX threads,
\item C++11 threads,
\item OpenMP,
\item MPI,
\item CUDA.
\end{itemize}
\end{multicols}

Wymienione warianty zostały zaimplementowane jako oddzielne klasy. Wersja jednowątkowa stanowi klasę bazową o nazwie \textbf{\texttt{Prime}}. Po klasie tej dziedziczą klasy \textbf{\texttt{PrimePosix}}, \textbf{\texttt{PrimeCpp11}}, \textbf{\texttt{PrimeOmp}}, \textbf{\texttt{PrimeMpi}} oraz \textbf{\texttt{PrimeCuda}} które implementują odpowiednio warianty POSIX threads, C++11 threads, OpenMP, MPI oraz CUDA.

Klasa bazowa \textbf{\texttt{Prime}} implementuje metody:
\begin{itemize}
\item statyczną \textbf{\texttt{Check()}},
\item \textbf{\texttt{Print()}},
\item wirtualną \textbf{\texttt{Find()}}.
\end{itemize}
Dwie pierwsze metody są używane przez wszystkie klasy na drodze dziedziczenia. Trzecia natomiast jest metodą wirtualną, aby mogła zostać nadpisana w klasach pochodnych.

\subsection{Klasa \textbf{\texttt{Prime}}}
Najważniejsza metoda klasy \textbf{\texttt{Prime}} to \textbf{\texttt{Check()}}. Jak wcześniej wspomniano jest ona wspólna dla wszystkich klas. Implementuje ona algorytm sprawdzania czy zadana liczba jest pierwsza czy nie. Nie jest to klasyczny algorytm sita Eratostenesa. Algorytm wykorzystuje fakt, że wszystkie liczby pierwsze większe lub równe 5 muszą mieć postać $6k - 1$ lub $6k + 1$, gdzie $k \in \mathbb{N}$. \cite{c1} Wykorzystanie tego spostrzeżenia zauważalnie redukuje czas obliczeń. Złożoność algorytmu to $O(n \cdot log(log(n)))$ dla każdej sprawdzanej liczby.

Metoda \textbf{\texttt{Print()}} drukuje w konsoli rezultat obliczeń.
Metoda \textbf{\texttt{Find()}} sprawdza po kolei wszystkie liczby w zadanym przedziale i w przypadku znalezienia liczby pierwszej dodaje je do listy liczb pierwszych.

\subsection{Klasa \textbf{\texttt{PrimePosix}}} \label{posixclass}
Klasa ta wykorzystuje mechanizm wielowątkowości opisany w ramach standardu \textbf{POSIX}. Definicja jest zawarta w standardowym nagłówku \textbf{\texttt{pthread.h}}, natomiast flaga przekazana kompilatorowi to \textbf{\texttt{-pthread}}. Klasa dziedziczy po \textbf{\texttt{Prime}} i nadpisuje ona jej metodę \textbf{\texttt{Find()}}. Metoda ta startuje wątki nazwane w kodzie jako \textbf{\texttt{Worker()}}. Strategia zrównoleglenia algorytmu polega na systemie zadań, które wykonują wątki. Wątków (a więc i instancji \textbf{\texttt{Worker()}}) jest tyle, ile zdefiniujemy w czasie kompilacji. Pojedynczym zadaniem jest sprawdzenie, czy kolejna liczba jest pierwsza. Kiedy wątek skończy zadanie, pobiera wartość licznika \textbf{\texttt{current\_}} i inkrementuje go. Licznik ten informuje, jaka jest bieżąca liczba, która wymaga sprawdzenia. Pobranie wartości licznika i inkrementacja jest wykonywana \textbf{atomowo}. \cite{c2} Jest to możliwe dzięki specjalnemu typowi \textbf{\texttt{std::atomic}} w języku C++. Zapewnia on atomowość wykonania tych dwóch operacji na poziomie instrukcji assemblera w jednym cyklu procesora. Dzięki temu uniknęliśmy wykorzystania mechanizmów synchronizacji takich, jak mutexy, które są bardzo drogie z punktu widzenia wydajności.

Każdy wątek posiada swoją własną listę znalezionych liczb pierwszych, która zawsze jest posortowana. Listą tą jest kontener STL o typie \textbf{\texttt{std::list}}, który stanowi  standardową implementację linked-listy. Kiedy program znajdzie już wszystkie liczby pierwsze w zadanym przedziale, następuje łączenie rezultatów wszystkich wątków. Łączenie rezultatów zostało wykonane metodą \textbf{\texttt{std::list::merge()}}, która wykonuje łączenie zachowując posortowanie całości (dzięki temu, że obie listy były od samego początku już posortowane). Procedura ta ma złożoność $O(n)$, a więc jest o wiele mniej kosztowna od przeszukiwania przedziału. Podczas łączenia list zastosowano synchronizację POSIX mutexem. Jest to konieczne, aby uniknąć utracenia spójności struktury zbiorczej linked-listy. Synchronizowanie to wykonywane jest przez każdy wątek raz (na końcu programu), więc jest to mało kosztowne.

\subsection{Klasa \textbf{\texttt{PrimeCpp11}}}
Klasa ta wykorzystuje mechanizm wielowątkowości opisany w ramach standardu \textbf{C++11}. Definicja jest zawarta w standardowym nagłówku \textbf{\texttt{thread}}, natomiast flaga przekazana kompilatorowi to \textbf{\texttt{-std=c++11}}. Mechanizm przydzielania zadań i łączenie rezultatów jest analogiczne jak w przypadku klasy \textbf{\texttt{PrimePosix}} opisanej w podrozdziale \ref{posixclass}.

\subsection{Klasa \textbf{\texttt{PrimeOmp}}}
Klasa ta wykorzystuje mechanizm wielowątkowości otwartego projektu \textbf{OpenMP}. Jest to zestaw dyrektyw kompilatora. Definicja jest zawarta w standardowym nagłówku \textbf{\texttt{omp.h}}, natomiast flaga przekazana kompilatorowi to \textbf{\texttt{-fopenmp}}. Implementacja zrównoleglania odróżnia się od tej przedstawionej w dwóch poprzednich klasach. Metoda \textbf{\texttt{Find()}} nie używa tutaj statycznej metody \textbf{\texttt{Worker()}}. Zamiast tego bezpośrednio używa dyrektywę preprocesora \textbf{\texttt{\#pragma omp parallel}}. Mechanizm ten jest dużo szybszy w implementacji, a zatem wygodniejszy dla programisty.

\subsection{Klasa \textbf{\texttt{PrimeMpi}}}
W tej klasie wykorzystana została biblioteka wspierającą MPI (Message Passing Interface), czyli protokół komunikacyjny do przesyłania komunikatów pomiędzy procesami programów równoległych działającymi na jednym lub więcej komputerach.  Biblioteka udostępnia narzędzie \textbf{\texttt{mpirun}} służące do uruchomienia programu, a poprzez podanie parametru \textbf{\texttt{-np}} ustawienie ile procesów ma zostać uruchomionych. Z powodu wykorzystania MPI klasa musiała zostać zaimplementowana jako niezależny program. Podczas inicjalizacji programu tworzony jest kanał komunikacyjny. Każdy z procesów dostaje indywidualny numer \textbf{\texttt{word\_rank}}, służący do indentyfikacji podczas komunikacji, oraz do podziału zadań. Główna część programu dzieli się na dwie fazy.

W pierwszej fazie procesy szukają liczb pierwszych. W celu uzyskania jak najlepszego czasu należało rozwiązać problem równomiernego obciążenia każdego z procesów. By unikniąć wysyłania wiadomości do procesów o tym jaki przedział mają przeszukiwać, wyznaczany jest on dynamicznie na podstawie indentyfikatora procesu nadanego przez MPI. Dziedzina została podzielona na $N^4$ tak samo licznych podzbiorów $Z_i$, gdzie $N$ oznacza liczbę procesów. Proces $N_i$ obsługuje $N^3$ zbiorów: $Z_{i+N*0}$, $Z_{i+N*1}$, ..., $Z_{i + N*N}$ ..., $Z_{i+ N*(N^3-1)}$. Taka granulacja powoduje, że każdy z procesów bierze udział w sprawdzaniu dużych liczb. Znalezione liczby pierwsze zapisywane są w \textbf{\texttt{task\_primes}}.

Druga faza następuje po sprawdzeniu wszystkich liczb i polega na przesłaniu wyników do głównego procesu. Za główny proces uznawany jest proces z indentyfikatorem o wartości $0$. Wysłanie wyników odbywa się za pomocą \textbf{MPI\_Send}. Główny proces przy pomocy \textbf{MPI\_Recv} odbiera wyniki od procesów i łączy je ze sobą. Po złączeniu wyników proces kończy pracę.      

\subsection{Klasa \textbf{\texttt{PrimeCuda}}}
Wersja zrealizowana w środowisku CUDA różni się nieco podejściem do zrównoleglania obliczeń. Typowa dla obliczeń na GPU jest bowiem \textbf{równoległość danych}, tj. realizacja tych samych obliczeń równocześnie na wielu niezależnych elementach danych.
Kod tej wersji programu można podzielić na dwie części: część wykonywaną na CPU oraz na GPU. Najpierw, dane z pamięci CPU muszą zostać skopiowane do pamięci GPU. Następnie, kod działający na CPU wywołuje funkcję napisaną dla GPU, czyli tzw. \textbf{kernel}. Program działający na GPU wykonuje kod równoległy, a na zakończenie rezultaty z~pamięci GPU przekazywane są zpowrotem do CPU.

Metoda \textbf{\texttt{Find()}} klasy \textbf{\texttt{PrimeCuda}} została zrealizowana następująco: wywołuje ona pomocniczą funkcję \texttt{cuda\_wrapper}, która przyjmuje końce przedziału $a$ i $b$ i zwraca listę znalezionych w tym przedziale liczb pierwszych. Wewnątrz funkcji tej tworzone są dwa wektory typu \texttt{bool} rozmiaru $b-a+1$ (jako \texttt{host\_vector} oraz \texttt{device\_vector} z biblioteki \texttt{thrust} -- pierwszy dla CPU, a drugi dla GPU), wypełnione początkowo wartościami \texttt{False}. Następnie, w $(b-a)/1000+1$ blokach po 1024 wątki, wywoływana jest funkcja \texttt{kernel} (oznaczona słowem kluczowym \texttt{\_\_global\_\_}). Pojedynczy kernel sprawdza, czy dana liczba (identyfikowana numerem bloku i wątku) jest liczbą pierwszą i wstawia odpowiednio \texttt{True} lub \texttt{False} w odpowiednim elemencie wektora \texttt{device\_vector} (kopia na GPU). Po zakończeniu wszystkich obliczeń na GPU następuje przekopiowanie wartości tego wektora do wektora \texttt{host\_vector}. Następnie, iterując po jego elementach, kolejne liczby pierwsze dodawane są do listy. Lista ta zwracana jest jako wynik funkcji \texttt{cuda\_wrapper}, a jej rozmiar odpowiada poszukiwanej wielkości zbioru liczb pierwszych w przedziale.

\subsection{Kompilacja programu}
Przed kompilacją należy zainstalować system budowania \textbf{CMake} w wersji minimum 3.5. Następnie należy ustalić docelową ilość wątków maszyny, na której będzie uruchamiany nasz program. Parametr \textbf{\texttt{NUM\_THREADS}} ustawia się w pliku \textbf{\texttt{CMakeLists.txt}}. Następnie możemy przystąpić do kompilacji naszego programu skryptem powłoki \textbf{\texttt{build.sh}}. Warianty programu wykonywane wyłącznie na CPU kompilowane są z użyciem \textbf{gcc}, natomiast wersja CUDA wymaga innego kompilatora: \textbf{nvcc}. Wyjściowy plik wykonywalny to \textbf{\texttt{prime\_finder}}.

\subsection{Uruchomienie programu}
Plik wykonywalny \textbf{\texttt{prime\_finder}} przyjmuje jako parametry początek i koniec przedziału poszukiwań liczb pierwszych. Składnia jest następująca: \textbf{\texttt{prime\_finder a b}}. Jeżeli chcemy szukać liczb pierwszych począwszy od 1000 do 10000000, należy wykonać \textbf{\texttt{prime\_finder 1000 10000000}}. Program zwróci nam ilość znalezionych liczb pierwszych i czas wykonania dla każdej z wyżej wymienionych technik zrównoleglenia.

\section{Prezentacja rezultatów}

\subsection{Etap 1}

Do testów w pierwszym etapie projektu użyto maszyny z czterordzeniowym procesorem Intel Xeon E5504. Procesor nie posiada technologii \textbf{Hyper-threading}. Oznacza, to ilość wątków logicznych widzianych przez system operacyjny odpowiada ilości fizycznych rdzeni procesora. Program został zatem skompilowany z flagą \textbf{\texttt{-DNUM\_THREADS=4}}.

Rezultaty możemy przedstawić na przykładzie uruchomienia: \textbf{\texttt{prime\_finder 1 100000000}}. Poniżej znajduje się wydruk ze standardowego wyjścia:

\begin{boxedverbatim}
mwaszak@livewire:~/prime_finder$ ./prime_finder 1 100000000
Threads number set to 4.
[Single] Primes found: 5761455
[POSIX]  Primes found: 5761455
[C++11]  Primes found: 5761455
[OpenMP] Primes found: 5761455

Times elapsed:
Single: 158.017 s
POSIX:  40.012 s
C++11:  40.005 s
OpenMP: 40.079 s
\end{boxedverbatim}

\subsection{Etap 2}
Testy w drugim etapie przeprowadzono na tej samej maszynie Intel Xeon E5504. Dodatkowo zainstalowano kartę graficzną NVIDIA GeForce GTX 960. Warto zauważyć poprawę czasów uzyskanych dla wersji CPU w porównaniu z otrzymanymi w pierwszym etapie - poprawa nastąpiła po zmianie typu zmiennych liczbowych z 64 bitów na 32 bity.

\begin{boxedverbatim}
mwaszak@livewire:~/prime_finder$ ./prime_finder 1 100000000
CPU threads number set to 4.
[Single] Primes found: 5761455
[POSIX]  Primes found: 5761455
[C++11]  Primes found: 5761455
[OpenMP] Primes found: 5761455
[MPI]    Primes found: 5761455
[CUDA]   Primes found: 5761455

Times elapsed:
Single: 97.575 s
POSIX:  24.888 s (speedup: 3.92)
C++11:  24.911 s (speedup: 3.92)
OpenMP: 24.558 s (speedup: 3.97)
MPI:    24.830 s (speedup: 3.93)
CUDA:   15.807 s (speedup: 6.17)
\end{boxedverbatim}

\subsection{Analiza rezultatów}
Każdy wariant zwrócił tę samą ilość liczb pierwszych, która jest zgodna z prawdą \cite{c3}. Jak widzimy, dla wariantów równoległych korzystających jedynie z CPU osiągnęto współczynnik przyspieszenia (\textit{ang. speed-up}) zadania rzędu 3,95 w porównaniu do wariantu jednowątkowego. Oznacza to, że zadanie zrównolegliło się niemal idealnie na wszystkich 4 rdzeniach procesora, co oznaczałoby osiągniecie przyspieszenia liniowego. Wartość współczynnika przyspieszenia można oszacowań wykorzystując prawo Amdahla \cite{c4}:
\begin{equation}
S(n,p)=\frac{T(n,p)}{T(1,p)}=\frac{1}{\beta(n,1)+\frac{1-\beta(n,1)}{p}}
\end{equation}
gdzie,
\begin{itemize}
\item $n$ – parametr opisujący wielkość zadania,
\item $p$ – liczba procesorów,
\item $T(n, p)$ – czas wykonania programu realizującego ten sam algorytm dla zadania o wielkości $n$ na maszynie z $p$ procesorami,
\item $\beta(n, p)$ – udział czasu wykonania części sekwencyjnej w programie o wielkości $n$ realizowanym na maszynie z $p$ procesorami w całym czasie rzeczywistym (zegarowym) wykonania programu $T(n, p)$.
\end{itemize}
Przyspieszenie liniowe ma miejsce, gdy brak w programie części sekwencyjnej (\textit{$\beta(n, p) = 0$}). Według prawa Amdahla współczynnik przyspieszenia wynosi wtedy:
\begin{equation}
S(n, p) = p
\end{equation}
co oznacza, że rośnie on proporcjonalnie do liczby procesorów wykorzystanych do rozwiązania zadania. Na tej podstawie możemy wywnioskować, że w naszym rozwiązaniu część sekwencyjna jest pomijalnie mała w porównaniu do części równoległej.

Ponadto w zaprezentowanym rozwiązaniu nie ma wielkich różnic między zbadanymi metodami zrównoleglania, żadna metoda nie wyróżnia się zwiększonym narzutem czasowym, wszystkie są równie dobre. Warto dodać, że zastosowane dzielenie zbioru dla MPI sprawdza się, procesy są niemal równomiernie obciążone. Testowanie przeprowadzane było wielokrotnie na różnych przedziałach i powyższe relacje czasowe były zawsze zachowane.

Najlepszy rezultat czasowy uzyskano korzystając z możliwości obliczeniowych GPU (przyspieszenie ponad sześciokrotne), jednak ciężko porównywać ten wynik z wynikami na CPU, gdyż zawdzięcza się go konkretnym parametrom sprzętowym. Prawdopodobnie uruchomienie programu na maszynie z lepszym procesorem pozwoliłoby osiągnąć podobne lub nawet lepsze rezultaty dla wersji CPU.

\printbibliography

\end{document}
